This repository provides supplementary material for our paper entitled _“Are Crowdsourcing Platforms Reliable for Video Game-related Research?” A Case Study on Amazon Mechanical Turk_, accepted to the Work-in-Progress track of the Annual Symposium on Computer-Human Interaction in Play (CHI PLAY'24).

If you use any of our resources, we kindly ask you to cite our paper with the following BibTeX entry:
```
@inproceedings{eisele2024crowdsourcing,
    title={{"Are Crowdsourcing Platforms Reliable for Video Game-related Research?" A Case Study on Amazon Mechanical Turk}},
    author={Eisele, Linus and Apruzzese, Giovanni},
    booktitle={Annual Symposium on Computer-Human Interaction in Play (CHI PLAY)},
    year={2024}
}
```

This repository includes:

* the three surveys (``wow_survey.pdf``, ``generic_survey.pdf``, ``lol_survey.pdf``) we used to carry out our research;
* the configuration of the batch for the generic survey on AMT (``AMTgeneric_config.pdf``);
* two screenshots of how our batch looks like when published on AMT (for the LoL ``mturk_lol.png`` and generic ``mturk_generic.png`` user studies).

For more information on the paper, you can refer to the personal webpage of Giovanni Apruzzese (https://www.giovanniapruzzese.com/publications/chiplay24).

Feel free to contact Linus Eisele for any inquiry.
